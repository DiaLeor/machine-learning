## Section 6.2 - Recommendation Systems

# Recommendation Systems --------------------------------------------------

# Recommendation systems are more complicated machine learning challenges because each outcome
# has a different set of predictors. For example, different users rate a different number of
# movies and rate different movies.

# To compare different models or to see how well we’re doing compared to a baseline, we will
# use root mean squared error (RMSE) as our loss function. We can interpret RMSE similar to
# standard deviation.

# If N is the number of user-movie combinations, y_u,i is the rating for movie i by user u, and
# y_hat_u,i is our prediction, then RMSE is defined as follows:
# sqrt((1/N) * the sum from u,i to n * (y_hat_u,i - y_u,i)^2)

# Recommendation systems use ratings that the users give an item on buying and/or using them to
# make specific recommendations.Companies like Amazon collect massive datasets of user ratings on
# the products sold to them. The datasets are subsequently used to predict a high rated items for
# a given user and are then recommended to the user.

# Similarly, Netflix use movie ratings provided by users to predict a high rated movie for a given
# user and then recommended it to the user. Usually the movie ratings are on a 1-5 scale, where
# 5 represents an excellent movie and 1 suggests it to be a poor one.

# Here we describe the basics of how the movie recommendations are made, motivated by some of 
# the approaches taken by the winners of the Netflix Challenges.

# In October 2006, Netflix offered a challenge on improving their movie recommendation system
# by 10% to win a prize money of a million dollars. The details of the challenge and the
# summary of the winning algorithm can be found in the Netflix Challenge links. Here we
# describe some of the data analysis strategies used by the winners of the challenge.

# Movielens data
# Though the Netflix data is not available publicly, a database with over 20 million ratings
# for over 27,000 movies rated by more than 138,000 was generated by the GroupLens research
# lab. We made a small subset of this data and the data is available in dslabs package.
# The data can be uploaded as follows:
library(dslabs)
library(tidyverse)
data("movielens")
# It can be viewed in a tidy format with thousands of rows.
# Each row in the table represents a rating given by one user to one movie.

# The number of unique users who provided ratings and the number unique movies that were
# rated can be viewed as follows:
movielens %>% 
  summarize(n_users = n_distinct(userId),
            n_movies = n_distinct(movieId))

# Multiplying the number of unique users (n_users = 671) and the number unique movies
# (n_movies = 9066) gives a total more than 5 million. However, our movielens data table
# has 100004 rows. This implies that not every movie is rated by every user. Therefore it
# is obvious that if we generate a table with the unique users as rows and the movies as columns,
# there will be a lot many empty cells. This is evident in a small example table consisting
# of seven users and five movies.

# Filling in the NAs in the above table can be thought as a task of recommendation system. The
# following matrix consisting of a random sample of 100 movies and 100 users show how sparse
# the matrix is. The yellow dots represent the user/movie combination for which a rating is
# available.

# In this machine learning challenge, suppose we are predicting the rating for movie i by user u.
# In that case, all ratings related to movie i and by user u may be used as predictors (not to
# forget that different users rate different movies and different number of movies). Also, ratings
# of movies similar to movie io and by users similar to user u may also be used as predictors.
# Thus for prediction of each outcome Y in this case, a different set of predictors can be used.

# Some general characteristics of the data: It is evident from the distributions plotted below
# that some movies are rated more than the other movies and some users are more active and rate
# more number of movies than the other users do.

# As a part of machine learning challenge, we need to build an algorithm with this data that
# we have collected. Others should be able to use the algorithm to suggest movies to users
# when they look for movie recommendations.

# We create train set and test set that is required to assess the accuracy of the models we
# implement. Here we use semi_join() function to ensure that we don’t include users and movies
# in the test set that do not appear in the training set. The code used for the purpose is
# as follows:
library(caret)
set.seed(755)
test_index <- createDataPartition(y = movielens$rating, times = 1,
                                  p = 0.2, list = FALSE)
train_set <- movielens[-test_index,]
test_set <- movielens[test_index,]

test_set <- test_set %>% 
  semi_join(train_set, by = "movieId") %>%
  semi_join(train_set, by = "userId")

# Loss function:To compare different models or to see how well we're doing compared to some
# baseline, the typical error loss, the residual mean squared error (RMSE) is used on the test
# set. We can interpret RMSE similar to standard deviation.

# If N is the number of user-movie combinations, y_u,i is the rating for movie i by user u, and
# y_hat_u,i is our prediction, then RMSE is defined as follows:
# sqrt((1/N) * the sum from u,i to n * (y_hat_u,i - y_u,i)^2)

# Building a Recommendation System ----------------------------------------

# We start with a model that assumes the same rating for all movies and all users, with all the
# differences explained by random variation: If mu represents the true rating for all movies and
# users and ∈ represents independent errors sampled from the same distribution centered at zero,
# then:
# Y_u,i = mu + ∈_u,i

# In this case, the least squares estimate of mu — the estimate that minimizes the root mean
# squared error — is the average rating of all movies across all users.

# We can improve our model by adding a term, b_i, that represents the average rating for movie i:
# Y_u,i = mu + b_i + ∈_u,i
# b_i is the average of Y_u,i minus the overall mean for each movie i

# We can further improve our model by adding b_u, the user-specific effect:
# Y_u,i = mu + b_i + b_u + ∈_u,i

# Note that because there are thousands of b's, the lm() function will be very slow or cause R
# to crash, so we don’t recommend using linear regression to calculate these effects.

# Notes of building the recommendation system

# A first model
# Building the first model- the simplest possible recommendation system: This model assumes
# the same rating for all movies and users with all the differences explained by random
# variation. The model is as follows:
# Y_u,i = mu + ∈_u,i
# where mu represents the true rating for all movies and users and ∈ represents independent
# errors sampled from the same distribution centered at zero.

# We know that the estimate that minimizes the RMSE is the least squares estimate of mu and,
# in this case, is the average of all ratings. Suppose mu_hat represents the average of all ratings
# and we use mu_hat to predict all the unknown movie ratings. From our data table, we obtain mu_hat
# and RMSE as shown below:
RMSE <- function(true_ratings, predicted_ratings){
  sqrt(mean((true_ratings - predicted_ratings)^2))
}

mu_hat <- mean(train_set$rating)
mu_hat

naive_rmse <- RMSE(test_set$rating, mu_hat)
naive_rmse
# The following code confirms that any number other than mu_hat would result into a higher RMSE.
predictions <- rep(2.5, nrow(test_set))
RMSE(test_set$rating, predictions)

# Modeling movie effects
# We know that some movies are just generally rated higher than others. Our first model can be
# improved by adding a term b_i that represents the average ranking for movie i. The improved
# model can be described as follows:
# Y_u,i = mu + b_i + ∈_u,i
# We can again use least squares to estimate the b_i in the following way:
fit <- lm(rating ~ as.factor(userId), data = movielens)
# However, the lm() function would be very slow here beacause there are thousands of b_i's as
# each movie gets a b_i. Therefore, we don't recommend running the code above. But in this
# particular situation, we know that the least squares estimate b_hat_i is just the average of
# Y_u,i - mu_hat for each movie i. So we can compute them as shown below (Note that to make the
# code look cleaner, we are not using the hat notation from this point onward):
mu <- mean(train_set$rating) 
movie_avgs <- train_set %>% 
  group_by(movieId) %>% 
  summarize(b_i = mean(rating - mu))

# We can see in the plot below that these estimates b_hat_i for movies vary substantially.
# This is not surprising as we know that some movies are good whereas others are not.

# We had estimated the mu_hat, the average of all ratings, as 3.5. So a b_hat_i of 1.5 implies
# y_hat_u,i = mu_hat + b_hat_i = 3.5 + 1.5 = 5 which is a perfect five-star rating.

# Now let's see how much our prediction improves once we predict using the model that we just
# fit. We can use this code and see that our residual mean squared error did drop a little bit.
predicted_ratings <- mu + test_set %>% 
  left_join(movie_avgs, by='movieId') %>%
  pull(b_i)

model_1_rmse <- RMSE(predicted_ratings, test_set$rating)
model_1_rmse

# Modeling user effects
# We use the following code to compute the average rating for user mu for those that have
# rated 100 or more movies and to plot the same.
train_set %>% 
  group_by(userId) %>% 
  summarize(b_u = mean(rating)) %>% 
  filter(n()>=100) %>%
  ggplot(aes(b_u)) + 
  geom_histogram(bins = 30, color = "black")

# The substantial variability across users is quiet evident from the above plot. This
# implies that a further improvement to our model may be:
# Y_u,i = mu + b_i + b_u + ∈_u,i
# where b_u is the user-specific effect. Now if a cranky user (negative b_u) rates a great
# movie (positive b_i), the effects counter each other and we may be able to correctly
# predict that this user gave this great movie a 3 rather than a 5.

# Though the above model can be fit with the following line of code, we don't recommend
# running the code for reasons explained earlier.
lm(rating ~ as.factor(movieId) + as.factor(userId))

# Instead, we will compute an approximation by computing mu_hat and b_hat_i and estimating
# b_hat_u as the average of y_hat_u,i - mu_hat - b_hat_i:
user_avgs <- train_set %>% 
  left_join(movie_avgs, by='movieId') %>%
  group_by(userId) %>%
  summarize(b_u = mean(rating - mu - b_i))

# We can now construct predictors and see how much the RMSE improves using the code below:
predicted_ratings <- test_set %>% 
  left_join(movie_avgs, by='movieId') %>%
  left_join(user_avgs, by='userId') %>%
  mutate(pred = mu + b_i + b_u) %>%
  pull(pred)

model_2_rmse <- RMSE(predicted_ratings, test_set$rating)
model_2_rmse