<p>Taking notes on the <a href="https://www.edx.org/course/data-science-machine-learning">Data Science: Machine Learning</a> course; practicing what I've learned during the previous <a href="https://www.edx.org/course/data-science-productivity-tools">Data Science: Productivity Tools</a> course. For most effective navigation in RStudio, document outine (Ctrl+Shift+O) aligns with the following .R contents:<br></p>
<br>
<p>--- Directory: <a href="[]">intro_to_ml</a> ---<br>
<br>
-- <a href="[]">1.1-notation.R</a><br>
- Section 1.1 - Notation<br>
<br>
&emsp;&emsp;- Notation - []<br>
&emsp;&emsp;<br>
&emsp;&emsp;- Example: Zip Code Reader - []<br>
&emsp;&emsp;<br></p>
<p><br>
<br></p>
<p>--- Directory: <a href="[]">ml_basics</a> ---<br>
<br>
-- <a href="[]">2.1-evaluation.R</a><br>
- Section 2.1 - Basics of Evaluation Machine Learning Algorithms<br>
<br>
&emsp;&emsp;- Evaluation Metrics - []<br>
&emsp;&emsp;<br>
&emsp;&emsp;- Confusion Matrix - []<br>
&emsp;&emsp;<br>
&emsp;&emsp;- Sensitivity, Specificity, and Prevalence - []<br>
&emsp;&emsp;<br>
&emsp;&emsp;- Balanced Accuracy and F1 Score - []<br>
&emsp;&emsp;<br>
&emsp;&emsp;- Prevalence Matters in Practice - []<br>
&emsp;&emsp;<br>
&emsp;&emsp;- ROC and Precision-Recall Curves - []<br>
&emsp;&emsp;<br>
&emsp;&emsp;- Loss Funciton - []<br>
&emsp;&emsp;<br>
-- <a href="[]">2.2-conditional-probabilities.R</a><br>
- Section 2.2 - Conditional Probabilities<br>
<br>
&emsp;&emsp;- Conditional Probabilites - []<br>
&emsp;&emsp;<br>
&emsp;&emsp;- Conditional Expectations - []<br>
&emsp;&emsp;<br></p>
<p><br>
<br></p>
<p>--- Directory: <a href="[]">prediction</a> ---<br>
<br>
-- <a href="[]">3.1-linear-regression.R</a><br>
- Section 3.1 - Basics of Evaluation Machine Learning Algorithms<br>
<br>
&emsp;&emsp;- Linear Regression for Prediciton - []<br>
&emsp;&emsp;<br>
-- <a href="[]">3.2-smoothing.R</a><br>
- Section 2.2 - Smoothing<br>
<br>
&emsp;&emsp;- Smoothing - []<br>
&emsp;&emsp;<br>
&emsp;&emsp;- Bin Smoothing - []<br>
&emsp;&emsp;<br>
&emsp;&emsp;- Local Weighted Regression (loess) - []<br>
&emsp;&emsp;<br>
&emsp;&emsp;- Beware of Default Smoothing Parameters - []<br>
&emsp;&emsp;<br>
&emsp;&emsp;- Connecting Smoothing to Machine Learning - []<br>
&emsp;&emsp;<br></p>
<p>--- Directory: <a href="[]">cross_validation_kNN</a> ---<br>
<br>
-- <a href="[]">4.1-kNN.R</a><br>
- Section 4.1 - k-Nearest Neighbors<br>
<br>
&emsp;&emsp;- k-Nearest-Neighbors (kNN) - []<br>
&emsp;&emsp;<br>
&emsp;&emsp;- Overtraining and Oversmoothing (kNN) - []<br>
&emsp;&emsp;<br>
-- <a href="[]">4.2-cross-validation.R</a><br>
- Section 4.2 - Cross Validation<br>
<br>
&emsp;&emsp;- Choosing k - []<br>
&emsp;&emsp;<br>
&emsp;&emsp;- Mathematical Description of Cross-Validation - []<br>
&emsp;&emsp;<br>
&emsp;&emsp;- k-fold Cross-Validation - []<br>
&emsp;&emsp;<br>
&emsp;&emsp;- Bootstrap - []<br>
&emsp;&emsp;<br>
<p>--- Directory: <a href="[]">caret</a> ---<br>
<br>
-- <a href="[]">5.1-caret.R</a><br>
- Section 5.1 - The Caret Package<br>
<br>
&emsp;&emsp;- Caret Package - []<br>
&emsp;&emsp;<br>
&emsp;&emsp;- Fitting with Loess - []<br>
&emsp;&emsp;<br>
&emsp;&emsp;- Trees and Random Forests - []<br>
&emsp;&emsp;<br>
-- <a href="[]">5.2-titanic.R</a><br>
- Section 5.2 - Titanic Exercises<br>
<br>
&emsp;&emsp;- Titanic Exercises Pt. 1 - []<br>
&emsp;&emsp;<br>
&emsp;&emsp;- Titanic Exercises Pt. 2  - []<br>
&emsp;&emsp;<br>
<p>--- Directory: <a href="[]">model_fitting_recommendation</a> ---<br>
<br>
-- <a href="[]">6.1-MNIST.R</a><br>
- Section 6.1 - Case Study: MNIST<br>
<br>
&emsp;&emsp;- MNIST Case Study: Preprocessing - []<br>
&emsp;&emsp;<br>
&emsp;&emsp;- MNIST Case Study: kNN - []<br>
&emsp;&emsp;<br>
&emsp;&emsp;- MNIST Case Study: Random Forest - []<br>
&emsp;&emsp;<br>
&emsp;&emsp;- MNIST Case Study: Variable Importance - []<br>
&emsp;&emsp;<br>
&emsp;&emsp;- Ensembles - []<br>
&emsp;&emsp;<br>
-- <a href="[]">6.2-recommendation.R</a><br>
- Section 6.2 - Recommendation Systems<br>
<br>
&emsp;&emsp;- Recommendation Systems - []<br>
&emsp;&emsp;<br>
&emsp;&emsp;- Building a Recommendation System - []<br>
&emsp;&emsp;<br>
-- <a href="[]">6.3-regularization</a><br>
- Section 6.1 - Regularization<br>
<br>
&emsp;&emsp;- Regularization - []<br>
&emsp;&emsp;<br>
&emsp;&emsp;- Matrix Factorization - []<br>
&emsp;&emsp;<br>
&emsp;&emsp;- SVD and PCA - []<br>
&emsp;&emsp;<br>
